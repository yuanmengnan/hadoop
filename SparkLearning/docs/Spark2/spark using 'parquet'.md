##Error

	  21:15:51.668 WARN org.apache.spark.sql.execution.command.DropTableCommand: org.apache.spark.sql.AnalysisException: Table or view not found: tbl;
	  org.apache.spark.sql.AnalysisException: Table or view not found: tbl;
	    at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)
	    at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:649)
	    at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:601)
	    at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:631)
	    at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:624)
	    at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:62)
	    at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:62)
	    at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)
	    at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:61)
	    at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:624)
	    at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:570)
	    at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:85)
	    at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:82)
	    at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)
	    at scala.collection.immutable.List.foldLeft(List.scala:84)
	    at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:82)
	    at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:74)
	    at scala.collection.immutable.List.foreach(List.scala:381)
	    at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:74)
	    at org.apache.spark.sql.hive.test.TestHiveQueryExecution.analyzed$lzycompute(TestHive.scala:558)
	    at org.apache.spark.sql.hive.test.TestHiveQueryExecution.analyzed(TestHive.scala:544)
	    at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:50)
	    at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:67)
	    at org.apache.spark.sql.SparkSession.table(SparkSession.scala:618)
	    at org.apache.spark.sql.execution.command.DropTableCommand.run(ddl.scala:203)
	    at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)
	    at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)
	    at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:67)
	    at org.apache.spark.sql.Dataset.<init>(Dataset.scala:183)
	    at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:68)
	    at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	    at org.apache.spark.sql.test.SQLTestUtils$$anonfun$withTable$1.apply(SQLTestUtils.scala:207)
	    at org.apache.spark.sql.test.SQLTestUtils$$anonfun$withTable$1.apply(SQLTestUtils.scala:206)
	    at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	    at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
	    at org.apache.spark.sql.test.SQLTestUtils$class.withTable(SQLTestUtils.scala:206)
	    at org.apache.spark.sql.execution.command.DDLSuite.withTable(DDLSuite.scala:121)
	    at org.apache.spark.sql.execution.command.DDLSuite$$anonfun$36.apply$mcV$sp(DDLSuite.scala:686)
	    at org.apache.spark.sql.execution.command.DDLSuite$$anonfun$36.apply(DDLSuite.scala:684)
	    at org.apache.spark.sql.execution.command.DDLSuite$$anonfun$36.apply(DDLSuite.scala:684)
	    at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	    at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	    at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	    at org.scalatest.Transformer.apply(Transformer.scala:22)
	    at org.scalatest.Transformer.apply(Transformer.scala:20)
	    at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	    at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:68)
	    at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	    at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	    at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	    at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	    at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	    at org.apache.spark.sql.hive.execution.HiveCatalogedDDLSuite.org$scalatest$BeforeAndAfterEach$$super$runTest(HiveDDLSuite.scala:45)
	    at org.scalatest.BeforeAndAfterEach$class.runTest(BeforeAndAfterEach.scala:255)
	    at org.apache.spark.sql.hive.execution.HiveCatalogedDDLSuite.runTest(HiveDDLSuite.scala:45)
	    at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	    at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	    at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	    at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	    at scala.collection.immutable.List.foreach(List.scala:381)
	    at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	    at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	    at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	    at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	    at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	    at org.scalatest.Suite$class.run(Suite.scala:1424)
	    at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	    at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	    at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	    at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	    at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	    at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:31)
	    at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	    at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	    at org.apache.spark.SparkFunSuite.run(SparkFunSuite.scala:31)
	    at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	    at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	    at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	    at scala.collection.immutable.List.foreach(List.scala:381)
	    at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	    at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	    at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	    at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	    at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	    at org.scalatest.tools.Runner$.run(Runner.scala:883)
	    at org.scalatest.tools.Runner.run(Runner.scala)
	    at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	    at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
	
	
	  no viable alternative at input ''parquet''(line 1, pos 37)
	
	  == SQL ==
	  CREATE TABLE tbl(a INT, b INT) USING 'parquet' CLUSTERED BY (a) SORTED BY (b) INTO 5 BUCKETS
	  -------------------------------------^^^
	
	  org.apache.spark.sql.catalyst.parser.ParseException: 
	  no viable alternative at input ''parquet''(line 1, pos 37)
	
	  == SQL ==
	  CREATE TABLE tbl(a INT, b INT) USING 'parquet' CLUSTERED BY (a) SORTED BY (b) INTO 5 BUCKETS
	  -------------------------------------^^^
	
	    at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:217)
	    at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:114)
	    at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:48)
	    at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(ParseDriver.scala:68)
	    at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	    at org.apache.spark.sql.test.SQLTestUtils$$anonfun$sql$1.apply(SQLTestUtils.scala:64)
	    at org.apache.spark.sql.test.SQLTestUtils$$anonfun$sql$1.apply(SQLTestUtils.scala:64)
	    at org.apache.spark.sql.execution.command.DDLSuite$$anonfun$36$$anonfun$apply$mcV$sp$6.apply$mcV$sp(DDLSuite.scala:687)
	    at org.apache.spark.sql.test.SQLTestUtils$class.withTable(SQLTestUtils.scala:205)
	    at org.apache.spark.sql.execution.command.DDLSuite.withTable(DDLSuite.scala:121)
	    at org.apache.spark.sql.execution.command.DDLSuite$$anonfun$36.apply$mcV$sp(DDLSuite.scala:686)
	    at org.apache.spark.sql.execution.command.DDLSuite$$anonfun$36.apply(DDLSuite.scala:684)
	    at org.apache.spark.sql.execution.command.DDLSuite$$anonfun$36.apply(DDLSuite.scala:684)
	    at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	    at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	    at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	    at org.scalatest.Transformer.apply(Transformer.scala:22)
	    at org.scalatest.Transformer.apply(Transformer.scala:20)
	    at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	    at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:68)
	    at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	    at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	    at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	    at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	    at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	    at org.apache.spark.sql.hive.execution.HiveCatalogedDDLSuite.org$scalatest$BeforeAndAfterEach$$super$runTest(HiveDDLSuite.scala:45)
	    at org.scalatest.BeforeAndAfterEach$class.runTest(BeforeAndAfterEach.scala:255)
	    at org.apache.spark.sql.hive.execution.HiveCatalogedDDLSuite.runTest(HiveDDLSuite.scala:45)
	    at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	    at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	    at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	    at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	    at scala.collection.immutable.List.foreach(List.scala:381)
	    at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	    at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	    at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	    at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	    at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	    at org.scalatest.Suite$class.run(Suite.scala:1424)
	    at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	    at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	    at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	    at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	    at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	    at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:31)
	    at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	    at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	    at org.apache.spark.SparkFunSuite.run(SparkFunSuite.scala:31)
	    at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	    at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	    at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	    at scala.collection.immutable.List.foreach(List.scala:381)
	    at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	    at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	    at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	    at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	    at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	    at org.scalatest.tools.Runner$.run(Runner.scala:883)
	    at org.scalatest.tools.Runner.run(Runner.scala)
	    at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	    at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
	

##conclusion

	Using need ''
	stored as and stored by no need ''